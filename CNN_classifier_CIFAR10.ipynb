{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import classifier_utils\n",
    "from classifier_utils import cnn_model, preprocess_img, get_class\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "import keras\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.models import Sequential, Model\n",
    "import vgg16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170246144/170498071 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (y_train[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array details (dimension, type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image resizing. Vgg16 takes minimum size of 48x48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "x_train_vgg = np.zeros((50000,64,64,3))\n",
    "\n",
    "for i in range(50000):\n",
    "    x_train_vgg[i] = transform.resize(x_train[i], (64, 64), order=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_of_dataset = 50000 #in case of CIFAR \n",
    "\n",
    "mask = np.random.rand(size_of_dataset) < 0.8  #array of boolean variables\n",
    "\n",
    "training_set = x_train_vgg[mask]\n",
    "training_labels = y_train[mask]\n",
    "\n",
    "validation_set = x_train_vgg[~mask]\n",
    "validation_labels = y_train[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1st model\n",
    "#IMG_SIZE = 32\n",
    "#2nd model\n",
    "IMG_SIZE = 64 \n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing amount of pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2nd model\n",
    "#x_train_vgg = x_train_vgg[0:50000] #bigger value\n",
    "#y_train_vgg = y_train[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39942, 1)\n"
     ]
    }
   ],
   "source": [
    "print (training_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why already calculated values? By default on .resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.16862745  0.18039216  0.17647059]\n",
      "   ..., \n",
      "   [ 0.59607843  0.49019608  0.4       ]\n",
      "   [ 0.58039216  0.48627451  0.40392157]\n",
      "   [ 0.58039216  0.48627451  0.40392157]]\n",
      "\n",
      "  [[ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.16862745  0.18039216  0.17647059]\n",
      "   ..., \n",
      "   [ 0.59607843  0.49019608  0.4       ]\n",
      "   [ 0.58039216  0.48627451  0.40392157]\n",
      "   [ 0.58039216  0.48627451  0.40392157]]\n",
      "\n",
      "  [[ 0.0627451   0.07843137  0.07843137]\n",
      "   [ 0.0627451   0.07843137  0.07843137]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.46666667  0.3254902   0.19607843]\n",
      "   [ 0.47843137  0.34117647  0.22352941]\n",
      "   [ 0.47843137  0.34117647  0.22352941]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.70588235  0.54509804  0.37647059]\n",
      "   [ 0.70588235  0.54509804  0.37647059]\n",
      "   [ 0.67843137  0.48235294  0.16470588]\n",
      "   ..., \n",
      "   [ 0.38039216  0.24313725  0.13333333]\n",
      "   [ 0.3254902   0.20784314  0.13333333]\n",
      "   [ 0.3254902   0.20784314  0.13333333]]\n",
      "\n",
      "  [[ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.65882353  0.50588235  0.36862745]\n",
      "   ..., \n",
      "   [ 0.59215686  0.4627451   0.32941176]\n",
      "   [ 0.48235294  0.36078431  0.28235294]\n",
      "   [ 0.48235294  0.36078431  0.28235294]]\n",
      "\n",
      "  [[ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.65882353  0.50588235  0.36862745]\n",
      "   ..., \n",
      "   [ 0.59215686  0.4627451   0.32941176]\n",
      "   [ 0.48235294  0.36078431  0.28235294]\n",
      "   [ 0.48235294  0.36078431  0.28235294]]]\n",
      "\n",
      "\n",
      " [[[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.43529412  0.4627451   0.43137255]\n",
      "   [ 0.43529412  0.4627451   0.43137255]\n",
      "   [ 0.40784314  0.43529412  0.40784314]\n",
      "   ..., \n",
      "   [ 0.2745098   0.29803922  0.29411765]\n",
      "   [ 0.30588235  0.32941176  0.32156863]\n",
      "   [ 0.30588235  0.32941176  0.32156863]]\n",
      "\n",
      "  [[ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.38823529  0.41568627  0.38431373]\n",
      "   ..., \n",
      "   [ 0.30980392  0.33333333  0.3254902 ]\n",
      "   [ 0.31372549  0.3372549   0.32941176]\n",
      "   [ 0.31372549  0.3372549   0.32941176]]\n",
      "\n",
      "  [[ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.38823529  0.41568627  0.38431373]\n",
      "   ..., \n",
      "   [ 0.30980392  0.33333333  0.3254902 ]\n",
      "   [ 0.31372549  0.3372549   0.32941176]\n",
      "   [ 0.31372549  0.3372549   0.32941176]]]\n",
      "\n",
      "\n",
      " [[[ 0.10980392  0.09803922  0.03921569]\n",
      "   [ 0.10980392  0.09803922  0.03921569]\n",
      "   [ 0.14509804  0.13333333  0.0745098 ]\n",
      "   ..., \n",
      "   [ 0.31764706  0.28235294  0.16862745]\n",
      "   [ 0.33333333  0.29803922  0.18431373]\n",
      "   [ 0.33333333  0.29803922  0.18431373]]\n",
      "\n",
      "  [[ 0.10980392  0.09803922  0.03921569]\n",
      "   [ 0.10980392  0.09803922  0.03921569]\n",
      "   [ 0.14509804  0.13333333  0.0745098 ]\n",
      "   ..., \n",
      "   [ 0.31764706  0.28235294  0.16862745]\n",
      "   [ 0.33333333  0.29803922  0.18431373]\n",
      "   [ 0.33333333  0.29803922  0.18431373]]\n",
      "\n",
      "  [[ 0.12941176  0.10980392  0.05098039]\n",
      "   [ 0.12941176  0.10980392  0.05098039]\n",
      "   [ 0.13333333  0.11764706  0.05490196]\n",
      "   ..., \n",
      "   [ 0.37647059  0.32156863  0.21960784]\n",
      "   [ 0.33333333  0.28235294  0.17647059]\n",
      "   [ 0.33333333  0.28235294  0.17647059]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.34509804  0.28235294  0.2       ]\n",
      "   [ 0.34509804  0.28235294  0.2       ]\n",
      "   [ 0.35294118  0.29019608  0.20392157]\n",
      "   ..., \n",
      "   [ 0.29803922  0.2745098   0.19215686]\n",
      "   [ 0.32156863  0.29803922  0.21568627]\n",
      "   [ 0.32156863  0.29803922  0.21568627]]\n",
      "\n",
      "  [[ 0.38039216  0.30588235  0.21960784]\n",
      "   [ 0.38039216  0.30588235  0.21960784]\n",
      "   [ 0.36862745  0.29411765  0.20784314]\n",
      "   ..., \n",
      "   [ 0.24705882  0.21960784  0.14509804]\n",
      "   [ 0.28235294  0.25490196  0.18039216]\n",
      "   [ 0.28235294  0.25490196  0.18039216]]\n",
      "\n",
      "  [[ 0.38039216  0.30588235  0.21960784]\n",
      "   [ 0.38039216  0.30588235  0.21960784]\n",
      "   [ 0.36862745  0.29411765  0.20784314]\n",
      "   ..., \n",
      "   [ 0.24705882  0.21960784  0.14509804]\n",
      "   [ 0.28235294  0.25490196  0.18039216]\n",
      "   [ 0.28235294  0.25490196  0.18039216]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.56862745  0.63137255  0.76078431]\n",
      "   [ 0.56862745  0.63137255  0.76078431]\n",
      "   [ 0.59215686  0.65098039  0.78039216]\n",
      "   ..., \n",
      "   [ 0.57254902  0.63921569  0.76470588]\n",
      "   [ 0.55686275  0.61960784  0.7372549 ]\n",
      "   [ 0.55686275  0.61960784  0.7372549 ]]\n",
      "\n",
      "  [[ 0.56862745  0.63137255  0.76078431]\n",
      "   [ 0.56862745  0.63137255  0.76078431]\n",
      "   [ 0.59215686  0.65098039  0.78039216]\n",
      "   ..., \n",
      "   [ 0.57254902  0.63921569  0.76470588]\n",
      "   [ 0.55686275  0.61960784  0.7372549 ]\n",
      "   [ 0.55686275  0.61960784  0.7372549 ]]\n",
      "\n",
      "  [[ 0.6         0.6627451   0.79215686]\n",
      "   [ 0.6         0.6627451   0.79215686]\n",
      "   [ 0.61176471  0.6745098   0.80392157]\n",
      "   ..., \n",
      "   [ 0.53333333  0.59607843  0.74117647]\n",
      "   [ 0.50588235  0.56862745  0.70196078]\n",
      "   [ 0.50588235  0.56862745  0.70196078]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.18431373  0.18823529  0.25882353]\n",
      "   [ 0.18431373  0.18823529  0.25882353]\n",
      "   [ 0.18039216  0.18431373  0.25490196]\n",
      "   ..., \n",
      "   [ 0.16078431  0.16862745  0.22745098]\n",
      "   [ 0.16078431  0.16862745  0.22745098]\n",
      "   [ 0.16078431  0.16862745  0.22745098]]\n",
      "\n",
      "  [[ 0.19215686  0.19607843  0.27058824]\n",
      "   [ 0.19215686  0.19607843  0.27058824]\n",
      "   [ 0.18039216  0.18431373  0.25490196]\n",
      "   ..., \n",
      "   [ 0.14117647  0.14901961  0.20784314]\n",
      "   [ 0.14509804  0.15294118  0.21176471]\n",
      "   [ 0.14509804  0.15294118  0.21176471]]\n",
      "\n",
      "  [[ 0.19215686  0.19607843  0.27058824]\n",
      "   [ 0.19215686  0.19607843  0.27058824]\n",
      "   [ 0.18039216  0.18431373  0.25490196]\n",
      "   ..., \n",
      "   [ 0.14117647  0.14901961  0.20784314]\n",
      "   [ 0.14509804  0.15294118  0.21176471]\n",
      "   [ 0.14509804  0.15294118  0.21176471]]]\n",
      "\n",
      "\n",
      " [[[ 1.          0.96078431  0.51764706]\n",
      "   [ 1.          0.96078431  0.51764706]\n",
      "   [ 0.99607843  0.96862745  0.5254902 ]\n",
      "   ..., \n",
      "   [ 0.44705882  0.2627451   0.10196078]\n",
      "   [ 0.4627451   0.26666667  0.10588235]\n",
      "   [ 0.4627451   0.26666667  0.10588235]]\n",
      "\n",
      "  [[ 1.          0.96078431  0.51764706]\n",
      "   [ 1.          0.96078431  0.51764706]\n",
      "   [ 0.99607843  0.96862745  0.5254902 ]\n",
      "   ..., \n",
      "   [ 0.44705882  0.2627451   0.10196078]\n",
      "   [ 0.4627451   0.26666667  0.10588235]\n",
      "   [ 0.4627451   0.26666667  0.10588235]]\n",
      "\n",
      "  [[ 0.99607843  0.95686275  0.51372549]\n",
      "   [ 0.99607843  0.95686275  0.51372549]\n",
      "   [ 0.99607843  0.96862745  0.52156863]\n",
      "   ..., \n",
      "   [ 0.42745098  0.25882353  0.10588235]\n",
      "   [ 0.44705882  0.26666667  0.10588235]\n",
      "   [ 0.44705882  0.26666667  0.10588235]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.94901961  0.58039216  0.25098039]\n",
      "   [ 0.94901961  0.58039216  0.25098039]\n",
      "   [ 0.94901961  0.58039216  0.24705882]\n",
      "   ..., \n",
      "   [ 0.99215686  0.70196078  0.31372549]\n",
      "   [ 0.96470588  0.66666667  0.2627451 ]\n",
      "   [ 0.96470588  0.66666667  0.2627451 ]]\n",
      "\n",
      "  [[ 0.9372549   0.58431373  0.25098039]\n",
      "   [ 0.9372549   0.58431373  0.25098039]\n",
      "   [ 0.94901961  0.58039216  0.24705882]\n",
      "   ..., \n",
      "   [ 0.98823529  0.70980392  0.31764706]\n",
      "   [ 0.99215686  0.70980392  0.29803922]\n",
      "   [ 0.99215686  0.70980392  0.29803922]]\n",
      "\n",
      "  [[ 0.9372549   0.58431373  0.25098039]\n",
      "   [ 0.9372549   0.58431373  0.25098039]\n",
      "   [ 0.94901961  0.58039216  0.24705882]\n",
      "   ..., \n",
      "   [ 0.98823529  0.70980392  0.31764706]\n",
      "   [ 0.99215686  0.70980392  0.29803922]\n",
      "   [ 0.99215686  0.70980392  0.29803922]]]\n",
      "\n",
      "\n",
      " [[[ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.72941176  0.81568627  0.9254902 ]\n",
      "   ..., \n",
      "   [ 0.6745098   0.76078431  0.87058824]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]]\n",
      "\n",
      "  [[ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.72941176  0.81568627  0.9254902 ]\n",
      "   ..., \n",
      "   [ 0.6745098   0.76078431  0.87058824]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]]\n",
      "\n",
      "  [[ 0.76078431  0.82352941  0.9372549 ]\n",
      "   [ 0.76078431  0.82352941  0.9372549 ]\n",
      "   [ 0.74901961  0.81176471  0.9254902 ]\n",
      "   ..., \n",
      "   [ 0.67058824  0.74901961  0.85490196]\n",
      "   [ 0.65490196  0.74509804  0.84705882]\n",
      "   [ 0.65490196  0.74509804  0.84705882]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.77647059  0.74509804  0.66666667]\n",
      "   [ 0.77647059  0.74509804  0.66666667]\n",
      "   [ 0.74117647  0.70980392  0.62352941]\n",
      "   ..., \n",
      "   [ 0.68627451  0.6627451   0.61176471]\n",
      "   [ 0.68627451  0.6627451   0.60392157]\n",
      "   [ 0.68627451  0.6627451   0.60392157]]\n",
      "\n",
      "  [[ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.74117647  0.70980392  0.63529412]\n",
      "   ..., \n",
      "   [ 0.76862745  0.74117647  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]]\n",
      "\n",
      "  [[ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.74117647  0.70980392  0.63529412]\n",
      "   ..., \n",
      "   [ 0.76862745  0.74117647  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]]]]\n"
     ]
    }
   ],
   "source": [
    "print (training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples from training set (64x64 and 32x32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f51026b5358>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5358506be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_image = training_set[28:29]\n",
    "plt.imshow(single_image[0])         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zdjecie warstwy: include_top=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first_model = cnn_model(IMG_SIZE,NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58195968/58889256 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "second_model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(64,64,3), pooling=max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model (remember to set NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = first_model\n",
    "model = second_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting all layers to trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers: layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to add last layer and activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.add(Dense(NUM_CLASSES, activation='softmax')) .add doesn't work for VGG16\n",
    "\n",
    "last = model.output\n",
    "\n",
    "x = Flatten()(last)\n",
    "preds = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(model.input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set optimizer for tweaks (leraning rate lr=0.001 to lr=0.0001) !Unquote Adam!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Adam=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam,loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39942 samples, validate on 10058 samples\n",
      "Epoch 1/1\n",
      "39942/39942 [==============================] - 252s - loss: 0.1244 - acc: 0.9563 - val_loss: 0.3599 - val_acc: 0.8966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50cb70c2b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1st model\n",
    "#model.fit(x_train, y_train, batch_size=128, epochs=10)\n",
    "#2nd model\n",
    "#model.fit(x_train_vgg, y_train_vgg, batch_size=128, epochs=2)\n",
    "model.fit(training_set, training_labels, batch_size=128, nb_epoch=1, validation_data=(validation_set, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set test size to 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "x_test_vgg = np.zeros((10000,64,64,3))\n",
    "\n",
    "for i in range(10000):\n",
    "    x_test_vgg[i] = transform.resize(x_test[i], (64, 64), order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print (x_test_vgg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 22s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38704311814904213, 0.88839999999999997]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_vgg, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
