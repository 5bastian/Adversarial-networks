{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import classifier_utils\n",
    "from classifier_utils import cnn_model, preprocess_img, get_class\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "import keras\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.models import Sequential, Model\n",
    "import vgg16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170377216/170498071 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (y_train[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array details (dimension, type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image resizing. Vgg16 takes minimum size of 48x48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "x_train_vgg = np.zeros((50000,64,64,3))\n",
    "\n",
    "for i in range(50000):\n",
    "    x_train_vgg[i] = transform.resize(x_train[i], (64, 64), order=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_of_dataset = 50000 #in case of CIFAR \n",
    "\n",
    "mask = np.random.rand(size_of_dataset) < 0.8  #array of boolean variables\n",
    "\n",
    "training_set = x_train_vgg[mask]\n",
    "training_labels = y_train[mask]\n",
    "\n",
    "validation_set = x_train_vgg[~mask]\n",
    "validation_labels = y_train[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1st model\n",
    "#IMG_SIZE = 32\n",
    "#2nd model\n",
    "IMG_SIZE = 64 \n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing amount of pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2nd model\n",
    "#x_train_vgg = x_train_vgg[0:50000] #bigger value\n",
    "#y_train_vgg = y_train[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40188, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print (training_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_train = x_train.astype('float32')/255 # now values are between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why already calculated values? By default on .resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.16862745  0.18039216  0.17647059]\n",
      "   ..., \n",
      "   [ 0.59607843  0.49019608  0.4       ]\n",
      "   [ 0.58039216  0.48627451  0.40392157]\n",
      "   [ 0.58039216  0.48627451  0.40392157]]\n",
      "\n",
      "  [[ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.16862745  0.18039216  0.17647059]\n",
      "   ..., \n",
      "   [ 0.59607843  0.49019608  0.4       ]\n",
      "   [ 0.58039216  0.48627451  0.40392157]\n",
      "   [ 0.58039216  0.48627451  0.40392157]]\n",
      "\n",
      "  [[ 0.0627451   0.07843137  0.07843137]\n",
      "   [ 0.0627451   0.07843137  0.07843137]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.46666667  0.3254902   0.19607843]\n",
      "   [ 0.47843137  0.34117647  0.22352941]\n",
      "   [ 0.47843137  0.34117647  0.22352941]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.70588235  0.54509804  0.37647059]\n",
      "   [ 0.70588235  0.54509804  0.37647059]\n",
      "   [ 0.67843137  0.48235294  0.16470588]\n",
      "   ..., \n",
      "   [ 0.38039216  0.24313725  0.13333333]\n",
      "   [ 0.3254902   0.20784314  0.13333333]\n",
      "   [ 0.3254902   0.20784314  0.13333333]]\n",
      "\n",
      "  [[ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.65882353  0.50588235  0.36862745]\n",
      "   ..., \n",
      "   [ 0.59215686  0.4627451   0.32941176]\n",
      "   [ 0.48235294  0.36078431  0.28235294]\n",
      "   [ 0.48235294  0.36078431  0.28235294]]\n",
      "\n",
      "  [[ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.65882353  0.50588235  0.36862745]\n",
      "   ..., \n",
      "   [ 0.59215686  0.4627451   0.32941176]\n",
      "   [ 0.48235294  0.36078431  0.28235294]\n",
      "   [ 0.48235294  0.36078431  0.28235294]]]\n",
      "\n",
      "\n",
      " [[[ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.49411765  0.5372549   0.53333333]\n",
      "   ..., \n",
      "   [ 0.34117647  0.35294118  0.27843137]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]]\n",
      "\n",
      "  [[ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.49411765  0.5372549   0.53333333]\n",
      "   ..., \n",
      "   [ 0.34117647  0.35294118  0.27843137]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]]\n",
      "\n",
      "  [[ 0.54901961  0.62745098  0.6627451 ]\n",
      "   [ 0.54901961  0.62745098  0.6627451 ]\n",
      "   [ 0.56862745  0.6         0.60392157]\n",
      "   ..., \n",
      "   [ 0.30196078  0.31372549  0.24313725]\n",
      "   [ 0.27843137  0.28627451  0.23921569]\n",
      "   [ 0.27843137  0.28627451  0.23921569]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.64705882  0.60392157  0.50196078]\n",
      "   [ 0.64705882  0.60392157  0.50196078]\n",
      "   [ 0.61176471  0.59607843  0.50980392]\n",
      "   ..., \n",
      "   [ 0.48235294  0.44705882  0.47058824]\n",
      "   [ 0.51372549  0.4745098   0.51372549]\n",
      "   [ 0.51372549  0.4745098   0.51372549]]\n",
      "\n",
      "  [[ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.61960784  0.58039216  0.47843137]\n",
      "   ..., \n",
      "   [ 0.56078431  0.5254902   0.55686275]\n",
      "   [ 0.56078431  0.52156863  0.56470588]\n",
      "   [ 0.56078431  0.52156863  0.56470588]]\n",
      "\n",
      "  [[ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.61960784  0.58039216  0.47843137]\n",
      "   ..., \n",
      "   [ 0.56078431  0.5254902   0.55686275]\n",
      "   [ 0.56078431  0.52156863  0.56470588]\n",
      "   [ 0.56078431  0.52156863  0.56470588]]]\n",
      "\n",
      "\n",
      " [[[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.43529412  0.4627451   0.43137255]\n",
      "   [ 0.43529412  0.4627451   0.43137255]\n",
      "   [ 0.40784314  0.43529412  0.40784314]\n",
      "   ..., \n",
      "   [ 0.2745098   0.29803922  0.29411765]\n",
      "   [ 0.30588235  0.32941176  0.32156863]\n",
      "   [ 0.30588235  0.32941176  0.32156863]]\n",
      "\n",
      "  [[ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.38823529  0.41568627  0.38431373]\n",
      "   ..., \n",
      "   [ 0.30980392  0.33333333  0.3254902 ]\n",
      "   [ 0.31372549  0.3372549   0.32941176]\n",
      "   [ 0.31372549  0.3372549   0.32941176]]\n",
      "\n",
      "  [[ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.38823529  0.41568627  0.38431373]\n",
      "   ..., \n",
      "   [ 0.30980392  0.33333333  0.3254902 ]\n",
      "   [ 0.31372549  0.3372549   0.32941176]\n",
      "   [ 0.31372549  0.3372549   0.32941176]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.61176471  0.62352941  0.64313725]\n",
      "   [ 0.61176471  0.62352941  0.64313725]\n",
      "   [ 0.60784314  0.61960784  0.63921569]\n",
      "   ..., \n",
      "   [ 0.61176471  0.63137255  0.64313725]\n",
      "   [ 0.60784314  0.62745098  0.63921569]\n",
      "   [ 0.60784314  0.62745098  0.63921569]]\n",
      "\n",
      "  [[ 0.61176471  0.62352941  0.64313725]\n",
      "   [ 0.61176471  0.62352941  0.64313725]\n",
      "   [ 0.60784314  0.61960784  0.63921569]\n",
      "   ..., \n",
      "   [ 0.61176471  0.63137255  0.64313725]\n",
      "   [ 0.60784314  0.62745098  0.63921569]\n",
      "   [ 0.60784314  0.62745098  0.63921569]]\n",
      "\n",
      "  [[ 0.61960784  0.63137255  0.65098039]\n",
      "   [ 0.61960784  0.63137255  0.65098039]\n",
      "   [ 0.61568627  0.62745098  0.64705882]\n",
      "   ..., \n",
      "   [ 0.61568627  0.63529412  0.64705882]\n",
      "   [ 0.61568627  0.63529412  0.64705882]\n",
      "   [ 0.61568627  0.63529412  0.64705882]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.62745098  0.64705882  0.65882353]\n",
      "   [ 0.62745098  0.64705882  0.65882353]\n",
      "   [ 0.62352941  0.64313725  0.65490196]\n",
      "   ..., \n",
      "   [ 0.61176471  0.64313725  0.65098039]\n",
      "   [ 0.60784314  0.63921569  0.64705882]\n",
      "   [ 0.60784314  0.63921569  0.64705882]]\n",
      "\n",
      "  [[ 0.61960784  0.63921569  0.65098039]\n",
      "   [ 0.61960784  0.63921569  0.65098039]\n",
      "   [ 0.61568627  0.63529412  0.64705882]\n",
      "   ..., \n",
      "   [ 0.59607843  0.62745098  0.63529412]\n",
      "   [ 0.59607843  0.62745098  0.63529412]\n",
      "   [ 0.59607843  0.62745098  0.63529412]]\n",
      "\n",
      "  [[ 0.61960784  0.63921569  0.65098039]\n",
      "   [ 0.61960784  0.63921569  0.65098039]\n",
      "   [ 0.61568627  0.63529412  0.64705882]\n",
      "   ..., \n",
      "   [ 0.59607843  0.62745098  0.63529412]\n",
      "   [ 0.59607843  0.62745098  0.63529412]\n",
      "   [ 0.59607843  0.62745098  0.63529412]]]\n",
      "\n",
      "\n",
      " [[[ 0.56862745  0.63137255  0.76078431]\n",
      "   [ 0.56862745  0.63137255  0.76078431]\n",
      "   [ 0.59215686  0.65098039  0.78039216]\n",
      "   ..., \n",
      "   [ 0.57254902  0.63921569  0.76470588]\n",
      "   [ 0.55686275  0.61960784  0.7372549 ]\n",
      "   [ 0.55686275  0.61960784  0.7372549 ]]\n",
      "\n",
      "  [[ 0.56862745  0.63137255  0.76078431]\n",
      "   [ 0.56862745  0.63137255  0.76078431]\n",
      "   [ 0.59215686  0.65098039  0.78039216]\n",
      "   ..., \n",
      "   [ 0.57254902  0.63921569  0.76470588]\n",
      "   [ 0.55686275  0.61960784  0.7372549 ]\n",
      "   [ 0.55686275  0.61960784  0.7372549 ]]\n",
      "\n",
      "  [[ 0.6         0.6627451   0.79215686]\n",
      "   [ 0.6         0.6627451   0.79215686]\n",
      "   [ 0.61176471  0.6745098   0.80392157]\n",
      "   ..., \n",
      "   [ 0.53333333  0.59607843  0.74117647]\n",
      "   [ 0.50588235  0.56862745  0.70196078]\n",
      "   [ 0.50588235  0.56862745  0.70196078]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.18431373  0.18823529  0.25882353]\n",
      "   [ 0.18431373  0.18823529  0.25882353]\n",
      "   [ 0.18039216  0.18431373  0.25490196]\n",
      "   ..., \n",
      "   [ 0.16078431  0.16862745  0.22745098]\n",
      "   [ 0.16078431  0.16862745  0.22745098]\n",
      "   [ 0.16078431  0.16862745  0.22745098]]\n",
      "\n",
      "  [[ 0.19215686  0.19607843  0.27058824]\n",
      "   [ 0.19215686  0.19607843  0.27058824]\n",
      "   [ 0.18039216  0.18431373  0.25490196]\n",
      "   ..., \n",
      "   [ 0.14117647  0.14901961  0.20784314]\n",
      "   [ 0.14509804  0.15294118  0.21176471]\n",
      "   [ 0.14509804  0.15294118  0.21176471]]\n",
      "\n",
      "  [[ 0.19215686  0.19607843  0.27058824]\n",
      "   [ 0.19215686  0.19607843  0.27058824]\n",
      "   [ 0.18039216  0.18431373  0.25490196]\n",
      "   ..., \n",
      "   [ 0.14117647  0.14901961  0.20784314]\n",
      "   [ 0.14509804  0.15294118  0.21176471]\n",
      "   [ 0.14509804  0.15294118  0.21176471]]]\n",
      "\n",
      "\n",
      " [[[ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.72941176  0.81568627  0.9254902 ]\n",
      "   ..., \n",
      "   [ 0.6745098   0.76078431  0.87058824]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]]\n",
      "\n",
      "  [[ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.72941176  0.81568627  0.9254902 ]\n",
      "   ..., \n",
      "   [ 0.6745098   0.76078431  0.87058824]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]]\n",
      "\n",
      "  [[ 0.76078431  0.82352941  0.9372549 ]\n",
      "   [ 0.76078431  0.82352941  0.9372549 ]\n",
      "   [ 0.74901961  0.81176471  0.9254902 ]\n",
      "   ..., \n",
      "   [ 0.67058824  0.74901961  0.85490196]\n",
      "   [ 0.65490196  0.74509804  0.84705882]\n",
      "   [ 0.65490196  0.74509804  0.84705882]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.77647059  0.74509804  0.66666667]\n",
      "   [ 0.77647059  0.74509804  0.66666667]\n",
      "   [ 0.74117647  0.70980392  0.62352941]\n",
      "   ..., \n",
      "   [ 0.68627451  0.6627451   0.61176471]\n",
      "   [ 0.68627451  0.6627451   0.60392157]\n",
      "   [ 0.68627451  0.6627451   0.60392157]]\n",
      "\n",
      "  [[ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.74117647  0.70980392  0.63529412]\n",
      "   ..., \n",
      "   [ 0.76862745  0.74117647  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]]\n",
      "\n",
      "  [[ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.74117647  0.70980392  0.63529412]\n",
      "   ..., \n",
      "   [ 0.76862745  0.74117647  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]]]]\n"
     ]
    }
   ],
   "source": [
    "print (training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples from training set (64x64 and 32x32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd7e77a7518>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC5FAFPhCJBAFvhAJRIEvRAJR4AuRQP4fPjGV8VGP0iMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda3dad2860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_image = training_set[28:29]\n",
    "plt.imshow(single_image[0])         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zdjecie warstwy: include_top=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first_model = cnn_model(IMG_SIZE,NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58564608/58889256 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "second_model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(64,64,3), pooling=max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model (remember to set NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = first_model\n",
    "model = second_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting all layers to trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:-2]: layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 2,359,808\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to add last layer and activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.add(Dense(NUM_CLASSES, activation='softmax')) .add doesn't work for VGG16\n",
    "\n",
    "last = model.output\n",
    "\n",
    "x = Flatten()(last)\n",
    "preds = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(model.input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 14,735,178\n",
      "Trainable params: 2,380,298\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set optimizer for tweaks (leraning rate lr=0.001 to lr=0.0001) !Unquote Adam!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adam=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40188 samples, validate on 9812 samples\n",
      "Epoch 1/10\n",
      "40188/40188 [==============================] - 99s - loss: 0.0564 - acc: 0.9829 - val_loss: 1.0278 - val_acc: 0.7805\n",
      "Epoch 2/10\n",
      "40188/40188 [==============================] - 100s - loss: 0.0698 - acc: 0.9772 - val_loss: 1.1884 - val_acc: 0.7618\n",
      "Epoch 3/10\n",
      " 7168/40188 [====>.........................] - ETA: 66s - loss: 0.0696 - acc: 0.9754"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-10e29cf055db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#2nd model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model.fit(x_train_vgg, y_train_vgg, batch_size=128, epochs=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#1st model\n",
    "#model.fit(x_train, y_train, batch_size=128, epochs=10)\n",
    "#2nd model\n",
    "#model.fit(x_train_vgg, y_train_vgg, batch_size=128, epochs=2)\n",
    "model.fit(training_set, training_labels, batch_size=128, nb_epoch=10, validation_data=(validation_set, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set test size to 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vgg = np.zeros((10000,64,64,3))\n",
    "\n",
    "for i in range(10000):\n",
    "    x_test_vgg[i] = transform.resize(x_test[i], (64, 64), order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (x_test_vgg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_vgg, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
