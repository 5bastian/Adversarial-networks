{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import classifier_utils\n",
    "from classifier_utils import cnn_model, preprocess_img, get_class\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "import keras\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.models import Sequential, Model\n",
    "import vgg16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print y_train[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array details (dimension, type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image resizing. Vgg16 takes minimum size of 48x48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pas_user/anaconda2/envs/tensor_virtenv/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "x_train_vgg = np.zeros((50000,64,64,3))\n",
    "\n",
    "for i in range(50000):\n",
    "    x_train_vgg[i] = transform.resize(x_train[i], (64, 64), order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1st model\n",
    "#IMG_SIZE = 32\n",
    "#2nd model\n",
    "IMG_SIZE = 64 \n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing amount of pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1st model\n",
    "x_train = x_train[0:5000]\n",
    "y_train = y_train[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f4afc9230582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "#print categories .count\n",
    "for i in len(y_train):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2nd model\n",
    "x_train_vgg = x_train_vgg[0:5000]\n",
    "y_train_vgg = y_train[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print x_train_vgg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')/255 # now values are between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why already calculated values? By default on .resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.16862745  0.18039216  0.17647059]\n",
      "   ..., \n",
      "   [ 0.59607843  0.49019608  0.4       ]\n",
      "   [ 0.58039216  0.48627451  0.40392157]\n",
      "   [ 0.58039216  0.48627451  0.40392157]]\n",
      "\n",
      "  [[ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.16862745  0.18039216  0.17647059]\n",
      "   ..., \n",
      "   [ 0.59607843  0.49019608  0.4       ]\n",
      "   [ 0.58039216  0.48627451  0.40392157]\n",
      "   [ 0.58039216  0.48627451  0.40392157]]\n",
      "\n",
      "  [[ 0.0627451   0.07843137  0.07843137]\n",
      "   [ 0.0627451   0.07843137  0.07843137]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.46666667  0.3254902   0.19607843]\n",
      "   [ 0.47843137  0.34117647  0.22352941]\n",
      "   [ 0.47843137  0.34117647  0.22352941]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.70588235  0.54509804  0.37647059]\n",
      "   [ 0.70588235  0.54509804  0.37647059]\n",
      "   [ 0.67843137  0.48235294  0.16470588]\n",
      "   ..., \n",
      "   [ 0.38039216  0.24313725  0.13333333]\n",
      "   [ 0.3254902   0.20784314  0.13333333]\n",
      "   [ 0.3254902   0.20784314  0.13333333]]\n",
      "\n",
      "  [[ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.65882353  0.50588235  0.36862745]\n",
      "   ..., \n",
      "   [ 0.59215686  0.4627451   0.32941176]\n",
      "   [ 0.48235294  0.36078431  0.28235294]\n",
      "   [ 0.48235294  0.36078431  0.28235294]]\n",
      "\n",
      "  [[ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.65882353  0.50588235  0.36862745]\n",
      "   ..., \n",
      "   [ 0.59215686  0.4627451   0.32941176]\n",
      "   [ 0.48235294  0.36078431  0.28235294]\n",
      "   [ 0.48235294  0.36078431  0.28235294]]]\n",
      "\n",
      "\n",
      " [[[ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.49411765  0.5372549   0.53333333]\n",
      "   ..., \n",
      "   [ 0.34117647  0.35294118  0.27843137]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]]\n",
      "\n",
      "  [[ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.49411765  0.5372549   0.53333333]\n",
      "   ..., \n",
      "   [ 0.34117647  0.35294118  0.27843137]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]]\n",
      "\n",
      "  [[ 0.54901961  0.62745098  0.6627451 ]\n",
      "   [ 0.54901961  0.62745098  0.6627451 ]\n",
      "   [ 0.56862745  0.6         0.60392157]\n",
      "   ..., \n",
      "   [ 0.30196078  0.31372549  0.24313725]\n",
      "   [ 0.27843137  0.28627451  0.23921569]\n",
      "   [ 0.27843137  0.28627451  0.23921569]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.64705882  0.60392157  0.50196078]\n",
      "   [ 0.64705882  0.60392157  0.50196078]\n",
      "   [ 0.61176471  0.59607843  0.50980392]\n",
      "   ..., \n",
      "   [ 0.48235294  0.44705882  0.47058824]\n",
      "   [ 0.51372549  0.4745098   0.51372549]\n",
      "   [ 0.51372549  0.4745098   0.51372549]]\n",
      "\n",
      "  [[ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.61960784  0.58039216  0.47843137]\n",
      "   ..., \n",
      "   [ 0.56078431  0.5254902   0.55686275]\n",
      "   [ 0.56078431  0.52156863  0.56470588]\n",
      "   [ 0.56078431  0.52156863  0.56470588]]\n",
      "\n",
      "  [[ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.61960784  0.58039216  0.47843137]\n",
      "   ..., \n",
      "   [ 0.56078431  0.5254902   0.55686275]\n",
      "   [ 0.56078431  0.52156863  0.56470588]\n",
      "   [ 0.56078431  0.52156863  0.56470588]]]\n",
      "\n",
      "\n",
      " [[[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.43529412  0.4627451   0.43137255]\n",
      "   [ 0.43529412  0.4627451   0.43137255]\n",
      "   [ 0.40784314  0.43529412  0.40784314]\n",
      "   ..., \n",
      "   [ 0.2745098   0.29803922  0.29411765]\n",
      "   [ 0.30588235  0.32941176  0.32156863]\n",
      "   [ 0.30588235  0.32941176  0.32156863]]\n",
      "\n",
      "  [[ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.38823529  0.41568627  0.38431373]\n",
      "   ..., \n",
      "   [ 0.30980392  0.33333333  0.3254902 ]\n",
      "   [ 0.31372549  0.3372549   0.32941176]\n",
      "   [ 0.31372549  0.3372549   0.32941176]]\n",
      "\n",
      "  [[ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.38823529  0.41568627  0.38431373]\n",
      "   ..., \n",
      "   [ 0.30980392  0.33333333  0.3254902 ]\n",
      "   [ 0.31372549  0.3372549   0.32941176]\n",
      "   [ 0.31372549  0.3372549   0.32941176]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.65490196  0.63921569  0.56862745]\n",
      "   [ 0.65490196  0.63921569  0.56862745]\n",
      "   [ 0.80784314  0.78823529  0.70980392]\n",
      "   ..., \n",
      "   [ 0.19607843  0.25098039  0.26666667]\n",
      "   [ 0.18039216  0.3372549   0.35294118]\n",
      "   [ 0.18039216  0.3372549   0.35294118]]\n",
      "\n",
      "  [[ 0.65490196  0.63921569  0.56862745]\n",
      "   [ 0.65490196  0.63921569  0.56862745]\n",
      "   [ 0.80784314  0.78823529  0.70980392]\n",
      "   ..., \n",
      "   [ 0.19607843  0.25098039  0.26666667]\n",
      "   [ 0.18039216  0.3372549   0.35294118]\n",
      "   [ 0.18039216  0.3372549   0.35294118]]\n",
      "\n",
      "  [[ 0.61176471  0.6         0.53333333]\n",
      "   [ 0.61176471  0.6         0.53333333]\n",
      "   [ 0.80784314  0.78823529  0.70980392]\n",
      "   ..., \n",
      "   [ 0.38823529  0.45098039  0.48235294]\n",
      "   [ 0.18823529  0.34509804  0.36862745]\n",
      "   [ 0.18823529  0.34509804  0.36862745]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.56078431  0.60784314  0.58823529]\n",
      "   [ 0.56078431  0.60784314  0.58823529]\n",
      "   [ 0.58039216  0.61568627  0.60392157]\n",
      "   ..., \n",
      "   [ 0.12156863  0.22745098  0.25882353]\n",
      "   [ 0.13333333  0.25882353  0.28627451]\n",
      "   [ 0.13333333  0.25882353  0.28627451]]\n",
      "\n",
      "  [[ 0.54509804  0.60392157  0.58431373]\n",
      "   [ 0.54509804  0.60392157  0.58431373]\n",
      "   [ 0.56470588  0.61568627  0.60784314]\n",
      "   ..., \n",
      "   [ 0.16470588  0.32156863  0.34117647]\n",
      "   [ 0.16470588  0.30588235  0.32941176]\n",
      "   [ 0.16470588  0.30588235  0.32941176]]\n",
      "\n",
      "  [[ 0.54509804  0.60392157  0.58431373]\n",
      "   [ 0.54509804  0.60392157  0.58431373]\n",
      "   [ 0.56470588  0.61568627  0.60784314]\n",
      "   ..., \n",
      "   [ 0.16470588  0.32156863  0.34117647]\n",
      "   [ 0.16470588  0.30588235  0.32941176]\n",
      "   [ 0.16470588  0.30588235  0.32941176]]]\n",
      "\n",
      "\n",
      " [[[ 0.60392157  0.59607843  0.49019608]\n",
      "   [ 0.60392157  0.59607843  0.49019608]\n",
      "   [ 0.61176471  0.60392157  0.50980392]\n",
      "   ..., \n",
      "   [ 0.51372549  0.50980392  0.38039216]\n",
      "   [ 0.60392157  0.58431373  0.43529412]\n",
      "   [ 0.60392157  0.58431373  0.43529412]]\n",
      "\n",
      "  [[ 0.60392157  0.59607843  0.49019608]\n",
      "   [ 0.60392157  0.59607843  0.49019608]\n",
      "   [ 0.61176471  0.60392157  0.50980392]\n",
      "   ..., \n",
      "   [ 0.51372549  0.50980392  0.38039216]\n",
      "   [ 0.60392157  0.58431373  0.43529412]\n",
      "   [ 0.60392157  0.58431373  0.43529412]]\n",
      "\n",
      "  [[ 0.63921569  0.58823529  0.43529412]\n",
      "   [ 0.63921569  0.58823529  0.43529412]\n",
      "   [ 0.69803922  0.65490196  0.49019608]\n",
      "   ..., \n",
      "   [ 0.65098039  0.64705882  0.4627451 ]\n",
      "   [ 0.65882353  0.64313725  0.45882353]\n",
      "   [ 0.65882353  0.64313725  0.45882353]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.61568627  0.62745098  0.42745098]\n",
      "   [ 0.61568627  0.62745098  0.42745098]\n",
      "   [ 0.57647059  0.6         0.40784314]\n",
      "   ..., \n",
      "   [ 0.74901961  0.89019608  0.45882353]\n",
      "   [ 0.67843137  0.84705882  0.41176471]\n",
      "   [ 0.67843137  0.84705882  0.41176471]]\n",
      "\n",
      "  [[ 0.6         0.58823529  0.4       ]\n",
      "   [ 0.6         0.58823529  0.4       ]\n",
      "   [ 0.58823529  0.62352941  0.38823529]\n",
      "   ..., \n",
      "   [ 0.73333333  0.92941176  0.42352941]\n",
      "   [ 0.76078431  0.96862745  0.44705882]\n",
      "   [ 0.76078431  0.96862745  0.44705882]]\n",
      "\n",
      "  [[ 0.6         0.58823529  0.4       ]\n",
      "   [ 0.6         0.58823529  0.4       ]\n",
      "   [ 0.58823529  0.62352941  0.38823529]\n",
      "   ..., \n",
      "   [ 0.73333333  0.92941176  0.42352941]\n",
      "   [ 0.76078431  0.96862745  0.44705882]\n",
      "   [ 0.76078431  0.96862745  0.44705882]]]\n",
      "\n",
      "\n",
      " [[[ 0.17647059  0.1254902   0.08235294]\n",
      "   [ 0.17647059  0.1254902   0.08235294]\n",
      "   [ 0.18823529  0.13333333  0.08235294]\n",
      "   ..., \n",
      "   [ 0.09019608  0.05490196  0.03921569]\n",
      "   [ 0.07843137  0.03921569  0.03137255]\n",
      "   [ 0.07843137  0.03921569  0.03137255]]\n",
      "\n",
      "  [[ 0.17647059  0.1254902   0.08235294]\n",
      "   [ 0.17647059  0.1254902   0.08235294]\n",
      "   [ 0.18823529  0.13333333  0.08235294]\n",
      "   ..., \n",
      "   [ 0.09019608  0.05490196  0.03921569]\n",
      "   [ 0.07843137  0.03921569  0.03137255]\n",
      "   [ 0.07843137  0.03921569  0.03137255]]\n",
      "\n",
      "  [[ 0.18431373  0.12941176  0.08235294]\n",
      "   [ 0.18431373  0.12941176  0.08235294]\n",
      "   [ 0.19607843  0.1372549   0.08627451]\n",
      "   ..., \n",
      "   [ 0.08627451  0.04313725  0.03921569]\n",
      "   [ 0.0745098   0.03137255  0.02745098]\n",
      "   [ 0.0745098   0.03137255  0.02745098]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.37647059  0.35294118  0.20784314]\n",
      "   [ 0.37647059  0.35294118  0.20784314]\n",
      "   [ 0.44705882  0.41568627  0.27058824]\n",
      "   ..., \n",
      "   [ 0.60392157  0.52941176  0.34901961]\n",
      "   [ 0.59607843  0.54509804  0.38039216]\n",
      "   [ 0.59607843  0.54509804  0.38039216]]\n",
      "\n",
      "  [[ 0.38039216  0.35686275  0.20392157]\n",
      "   [ 0.38039216  0.35686275  0.20392157]\n",
      "   [ 0.33333333  0.30980392  0.15686275]\n",
      "   ..., \n",
      "   [ 0.61176471  0.5372549   0.36470588]\n",
      "   [ 0.61176471  0.55686275  0.39215686]\n",
      "   [ 0.61176471  0.55686275  0.39215686]]\n",
      "\n",
      "  [[ 0.38039216  0.35686275  0.20392157]\n",
      "   [ 0.38039216  0.35686275  0.20392157]\n",
      "   [ 0.33333333  0.30980392  0.15686275]\n",
      "   ..., \n",
      "   [ 0.61176471  0.5372549   0.36470588]\n",
      "   [ 0.61176471  0.55686275  0.39215686]\n",
      "   [ 0.61176471  0.55686275  0.39215686]]]]\n"
     ]
    }
   ],
   "source": [
    "print x_train_vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples from training set (64x64 and 32x32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f693cf30b10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f693cf9ae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_image = x_train_vgg[28:29]\n",
    "plt.imshow(single_image[0])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image = x_train[300:301]\n",
    "plt.imshow(single_image[0])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zdjecie warstwy: include_top=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first_model = cnn_model(IMG_SIZE,NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(64,64,3), pooling=max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model (remember to set NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = first_model\n",
    "model = second_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x7f6a0ef2a0d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ef93450>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ef93fd0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f6a0ef93ed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6b3d41be10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ee6c8d0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f6a0eedd250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ededfd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ee00e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ee15e10>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f6a0ee23dd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ede0b10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ed74a10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ed85810>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f6a0ed9a9d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ed55f50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ed55d90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ecfded0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f6a0ed0fe50>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing layers (for VGG16 additional layer, all previous layers need to be frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers: layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to add last layer and activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dense(NUM_CLASSES, activation='softmax')) .add doesn't work for VGG16\n",
    "\n",
    "last = model.output\n",
    "\n",
    "x = Flatten()(last)\n",
    "preds = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(model.input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x7f6a0ef2a0d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ef93450>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ef93fd0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f6a0ef93ed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6b3d41be10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ee6c8d0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f6a0eedd250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ededfd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ee00e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ee15e10>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f6a0ee23dd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ede0b10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ed74a10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ed85810>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f6a0ed9a9d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ed55f50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ed55d90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6a0ecfded0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f6a0ed0fe50>,\n",
       " <keras.layers.core.Flatten at 0x7f6a0ec70510>,\n",
       " <keras.layers.core.Dense at 0x7f6a0ee6cbd0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 14,735,178\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 128s - loss: 0.6628 - acc: 0.7994   \n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 126s - loss: 0.6497 - acc: 0.8066   \n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 125s - loss: 0.6392 - acc: 0.8096   \n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 126s - loss: 0.6248 - acc: 0.8144   \n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 126s - loss: 0.6152 - acc: 0.8160   \n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 126s - loss: 0.6054 - acc: 0.8236   \n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 126s - loss: 0.5972 - acc: 0.8270   \n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 125s - loss: 0.5877 - acc: 0.8240   \n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 126s - loss: 0.5814 - acc: 0.8316   \n",
      "Epoch 10/10\n",
      "3456/5000 [===================>..........] - ETA: 39s - loss: 0.5793 - acc: 0.8325"
     ]
    }
   ],
   "source": [
    "#1st model\n",
    "#model.fit(x_train, y_train, batch_size=128, epochs=10)\n",
    "#2nd model\n",
    "model.fit(x_train_vgg, y_train_vgg, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set test size to 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
