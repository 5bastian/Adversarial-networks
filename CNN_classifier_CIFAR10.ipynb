{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/matplotlib/font_manager.py:280: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import classifier_utils\n",
    "from classifier_utils import cnn_model, preprocess_img, get_class\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "import keras\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.models import Sequential, Model\n",
    "import vgg16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170319872/170498071 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print y_train[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array details (dimension, type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image resizing. Vgg16 takes minimum size of 48x48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "x_train_vgg = np.zeros((50000,64,64,3))\n",
    "\n",
    "for i in range(50000):\n",
    "    x_train_vgg[i] = transform.resize(x_train[i], (64, 64), order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1st model\n",
    "#IMG_SIZE = 32\n",
    "#2nd model\n",
    "IMG_SIZE = 64 \n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing amount of pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1st model\n",
    "x_train = x_train[0:5000]\n",
    "y_train = y_train[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2nd model\n",
    "x_train_vgg = x_train_vgg[0:50000] #bigger value\n",
    "y_train_vgg = y_train[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print (x_train_vgg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')/255 # now values are between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why already calculated values? By default on .resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.16862745  0.18039216  0.17647059]\n",
      "   ..., \n",
      "   [ 0.59607843  0.49019608  0.4       ]\n",
      "   [ 0.58039216  0.48627451  0.40392157]\n",
      "   [ 0.58039216  0.48627451  0.40392157]]\n",
      "\n",
      "  [[ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.16862745  0.18039216  0.17647059]\n",
      "   ..., \n",
      "   [ 0.59607843  0.49019608  0.4       ]\n",
      "   [ 0.58039216  0.48627451  0.40392157]\n",
      "   [ 0.58039216  0.48627451  0.40392157]]\n",
      "\n",
      "  [[ 0.0627451   0.07843137  0.07843137]\n",
      "   [ 0.0627451   0.07843137  0.07843137]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.46666667  0.3254902   0.19607843]\n",
      "   [ 0.47843137  0.34117647  0.22352941]\n",
      "   [ 0.47843137  0.34117647  0.22352941]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.70588235  0.54509804  0.37647059]\n",
      "   [ 0.70588235  0.54509804  0.37647059]\n",
      "   [ 0.67843137  0.48235294  0.16470588]\n",
      "   ..., \n",
      "   [ 0.38039216  0.24313725  0.13333333]\n",
      "   [ 0.3254902   0.20784314  0.13333333]\n",
      "   [ 0.3254902   0.20784314  0.13333333]]\n",
      "\n",
      "  [[ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.65882353  0.50588235  0.36862745]\n",
      "   ..., \n",
      "   [ 0.59215686  0.4627451   0.32941176]\n",
      "   [ 0.48235294  0.36078431  0.28235294]\n",
      "   [ 0.48235294  0.36078431  0.28235294]]\n",
      "\n",
      "  [[ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.65882353  0.50588235  0.36862745]\n",
      "   ..., \n",
      "   [ 0.59215686  0.4627451   0.32941176]\n",
      "   [ 0.48235294  0.36078431  0.28235294]\n",
      "   [ 0.48235294  0.36078431  0.28235294]]]\n",
      "\n",
      "\n",
      " [[[ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.49411765  0.5372549   0.53333333]\n",
      "   ..., \n",
      "   [ 0.34117647  0.35294118  0.27843137]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]]\n",
      "\n",
      "  [[ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.49411765  0.5372549   0.53333333]\n",
      "   ..., \n",
      "   [ 0.34117647  0.35294118  0.27843137]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]]\n",
      "\n",
      "  [[ 0.54901961  0.62745098  0.6627451 ]\n",
      "   [ 0.54901961  0.62745098  0.6627451 ]\n",
      "   [ 0.56862745  0.6         0.60392157]\n",
      "   ..., \n",
      "   [ 0.30196078  0.31372549  0.24313725]\n",
      "   [ 0.27843137  0.28627451  0.23921569]\n",
      "   [ 0.27843137  0.28627451  0.23921569]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.64705882  0.60392157  0.50196078]\n",
      "   [ 0.64705882  0.60392157  0.50196078]\n",
      "   [ 0.61176471  0.59607843  0.50980392]\n",
      "   ..., \n",
      "   [ 0.48235294  0.44705882  0.47058824]\n",
      "   [ 0.51372549  0.4745098   0.51372549]\n",
      "   [ 0.51372549  0.4745098   0.51372549]]\n",
      "\n",
      "  [[ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.61960784  0.58039216  0.47843137]\n",
      "   ..., \n",
      "   [ 0.56078431  0.5254902   0.55686275]\n",
      "   [ 0.56078431  0.52156863  0.56470588]\n",
      "   [ 0.56078431  0.52156863  0.56470588]]\n",
      "\n",
      "  [[ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.61960784  0.58039216  0.47843137]\n",
      "   ..., \n",
      "   [ 0.56078431  0.5254902   0.55686275]\n",
      "   [ 0.56078431  0.52156863  0.56470588]\n",
      "   [ 0.56078431  0.52156863  0.56470588]]]\n",
      "\n",
      "\n",
      " [[[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.43529412  0.4627451   0.43137255]\n",
      "   [ 0.43529412  0.4627451   0.43137255]\n",
      "   [ 0.40784314  0.43529412  0.40784314]\n",
      "   ..., \n",
      "   [ 0.2745098   0.29803922  0.29411765]\n",
      "   [ 0.30588235  0.32941176  0.32156863]\n",
      "   [ 0.30588235  0.32941176  0.32156863]]\n",
      "\n",
      "  [[ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.38823529  0.41568627  0.38431373]\n",
      "   ..., \n",
      "   [ 0.30980392  0.33333333  0.3254902 ]\n",
      "   [ 0.31372549  0.3372549   0.32941176]\n",
      "   [ 0.31372549  0.3372549   0.32941176]]\n",
      "\n",
      "  [[ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.38823529  0.41568627  0.38431373]\n",
      "   ..., \n",
      "   [ 0.30980392  0.33333333  0.3254902 ]\n",
      "   [ 0.31372549  0.3372549   0.32941176]\n",
      "   [ 0.31372549  0.3372549   0.32941176]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.1372549   0.69803922  0.92156863]\n",
      "   [ 0.1372549   0.69803922  0.92156863]\n",
      "   [ 0.15686275  0.69019608  0.9372549 ]\n",
      "   ..., \n",
      "   [ 0.30980392  0.57647059  0.77254902]\n",
      "   [ 0.34901961  0.58039216  0.74117647]\n",
      "   [ 0.34901961  0.58039216  0.74117647]]\n",
      "\n",
      "  [[ 0.1372549   0.69803922  0.92156863]\n",
      "   [ 0.1372549   0.69803922  0.92156863]\n",
      "   [ 0.15686275  0.69019608  0.9372549 ]\n",
      "   ..., \n",
      "   [ 0.30980392  0.57647059  0.77254902]\n",
      "   [ 0.34901961  0.58039216  0.74117647]\n",
      "   [ 0.34901961  0.58039216  0.74117647]]\n",
      "\n",
      "  [[ 0.22352941  0.71372549  0.91764706]\n",
      "   [ 0.22352941  0.71372549  0.91764706]\n",
      "   [ 0.17254902  0.72156863  0.98039216]\n",
      "   ..., \n",
      "   [ 0.55294118  0.69411765  0.80784314]\n",
      "   [ 0.45490196  0.58431373  0.68627451]\n",
      "   [ 0.45490196  0.58431373  0.68627451]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.23921569  0.26666667  0.29411765]\n",
      "   [ 0.23921569  0.26666667  0.29411765]\n",
      "   [ 0.21568627  0.2745098   0.3372549 ]\n",
      "   ..., \n",
      "   [ 0.06666667  0.1372549   0.20784314]\n",
      "   [ 0.02745098  0.09019608  0.1254902 ]\n",
      "   [ 0.02745098  0.09019608  0.1254902 ]]\n",
      "\n",
      "  [[ 0.17254902  0.21960784  0.28627451]\n",
      "   [ 0.17254902  0.21960784  0.28627451]\n",
      "   [ 0.18039216  0.25882353  0.34509804]\n",
      "   ..., \n",
      "   [ 0.08235294  0.16862745  0.25882353]\n",
      "   [ 0.04705882  0.12156863  0.19607843]\n",
      "   [ 0.04705882  0.12156863  0.19607843]]\n",
      "\n",
      "  [[ 0.17254902  0.21960784  0.28627451]\n",
      "   [ 0.17254902  0.21960784  0.28627451]\n",
      "   [ 0.18039216  0.25882353  0.34509804]\n",
      "   ..., \n",
      "   [ 0.08235294  0.16862745  0.25882353]\n",
      "   [ 0.04705882  0.12156863  0.19607843]\n",
      "   [ 0.04705882  0.12156863  0.19607843]]]\n",
      "\n",
      "\n",
      " [[[ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.72941176  0.81568627  0.9254902 ]\n",
      "   ..., \n",
      "   [ 0.6745098   0.76078431  0.87058824]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]]\n",
      "\n",
      "  [[ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.72941176  0.81568627  0.9254902 ]\n",
      "   ..., \n",
      "   [ 0.6745098   0.76078431  0.87058824]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]]\n",
      "\n",
      "  [[ 0.76078431  0.82352941  0.9372549 ]\n",
      "   [ 0.76078431  0.82352941  0.9372549 ]\n",
      "   [ 0.74901961  0.81176471  0.9254902 ]\n",
      "   ..., \n",
      "   [ 0.67058824  0.74901961  0.85490196]\n",
      "   [ 0.65490196  0.74509804  0.84705882]\n",
      "   [ 0.65490196  0.74509804  0.84705882]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.77647059  0.74509804  0.66666667]\n",
      "   [ 0.77647059  0.74509804  0.66666667]\n",
      "   [ 0.74117647  0.70980392  0.62352941]\n",
      "   ..., \n",
      "   [ 0.68627451  0.6627451   0.61176471]\n",
      "   [ 0.68627451  0.6627451   0.60392157]\n",
      "   [ 0.68627451  0.6627451   0.60392157]]\n",
      "\n",
      "  [[ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.74117647  0.70980392  0.63529412]\n",
      "   ..., \n",
      "   [ 0.76862745  0.74117647  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]]\n",
      "\n",
      "  [[ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.74117647  0.70980392  0.63529412]\n",
      "   ..., \n",
      "   [ 0.76862745  0.74117647  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]]]\n",
      "\n",
      "\n",
      " [[[ 0.89803922  0.89803922  0.9372549 ]\n",
      "   [ 0.89803922  0.89803922  0.9372549 ]\n",
      "   [ 0.9254902   0.92941176  0.96862745]\n",
      "   ..., \n",
      "   [ 0.86666667  0.8745098   0.91764706]\n",
      "   [ 0.87058824  0.8745098   0.91372549]\n",
      "   [ 0.87058824  0.8745098   0.91372549]]\n",
      "\n",
      "  [[ 0.89803922  0.89803922  0.9372549 ]\n",
      "   [ 0.89803922  0.89803922  0.9372549 ]\n",
      "   [ 0.9254902   0.92941176  0.96862745]\n",
      "   ..., \n",
      "   [ 0.86666667  0.8745098   0.91764706]\n",
      "   [ 0.87058824  0.8745098   0.91372549]\n",
      "   [ 0.87058824  0.8745098   0.91372549]]\n",
      "\n",
      "  [[ 0.87058824  0.86666667  0.89803922]\n",
      "   [ 0.87058824  0.86666667  0.89803922]\n",
      "   [ 0.9372549   0.9372549   0.97647059]\n",
      "   ..., \n",
      "   [ 0.89019608  0.89411765  0.93333333]\n",
      "   [ 0.82352941  0.82745098  0.8627451 ]\n",
      "   [ 0.82352941  0.82745098  0.8627451 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.5372549   0.51764706  0.49411765]\n",
      "   [ 0.5372549   0.51764706  0.49411765]\n",
      "   [ 0.50980392  0.49803922  0.47058824]\n",
      "   ..., \n",
      "   [ 0.79215686  0.78823529  0.77647059]\n",
      "   [ 0.83137255  0.82745098  0.81176471]\n",
      "   [ 0.83137255  0.82745098  0.81176471]]\n",
      "\n",
      "  [[ 0.47843137  0.46666667  0.44705882]\n",
      "   [ 0.47843137  0.46666667  0.44705882]\n",
      "   [ 0.4627451   0.45490196  0.43137255]\n",
      "   ..., \n",
      "   [ 0.64313725  0.64313725  0.63529412]\n",
      "   [ 0.63921569  0.63921569  0.63137255]\n",
      "   [ 0.63921569  0.63921569  0.63137255]]\n",
      "\n",
      "  [[ 0.47843137  0.46666667  0.44705882]\n",
      "   [ 0.47843137  0.46666667  0.44705882]\n",
      "   [ 0.4627451   0.45490196  0.43137255]\n",
      "   ..., \n",
      "   [ 0.64313725  0.64313725  0.63529412]\n",
      "   [ 0.63921569  0.63921569  0.63137255]\n",
      "   [ 0.63921569  0.63921569  0.63137255]]]]\n"
     ]
    }
   ],
   "source": [
    "print (x_train_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples from training set (64x64 and 32x32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1cd87835c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLFQG6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e09656940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_image = x_train_vgg[28:29]\n",
    "plt.imshow(single_image[0])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_image = x_train[300:301]\n",
    "plt.imshow(single_image[0])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zdjecie warstwy: include_top=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first_model = cnn_model(IMG_SIZE,NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "57737216/58889256 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "second_model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(64,64,3), pooling=max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model (remember to set NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = first_model\n",
    "model = second_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x7f1cd8783f98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd879ab00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd879a710>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f1cd86e6cc0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd870ef98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd8720fd0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f1cd86af630>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd86ca780>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd86ca208>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd86d8eb8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f1cd86815f8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd869e4e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd869e2e8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd863aef0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f1cd8658550>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd85e74a8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd85f3ef0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd8600588>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f1cd860fef0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting all layers to trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers: layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to add last layer and activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.add(Dense(NUM_CLASSES, activation='softmax')) .add doesn't work for VGG16\n",
    "\n",
    "last = model.output\n",
    "\n",
    "x = Flatten()(last)\n",
    "preds = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(model.input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x7f1cd8783f98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd879ab00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd879a710>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f1cd86e6cc0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd870ef98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd8720fd0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f1cd86af630>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd86ca780>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd86ca208>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd86d8eb8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f1cd86815f8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd869e4e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd869e2e8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd863aef0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f1cd8658550>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd85e74a8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd85f3ef0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f1cd8600588>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f1cd860fef0>,\n",
       " <keras.layers.core.Flatten at 0x7f1cd85d51d0>,\n",
       " <keras.layers.core.Dense at 0x7f1cd85d5048>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 14,735,178\n",
      "Trainable params: 14,735,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set optimizer for tweaks (leraning rate lr=0.001 to lr=0.0001) !Unquote Adam!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Adam=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam,loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 369s - loss: 0.5970 - acc: 0.7935   \n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 306s - loss: 0.2689 - acc: 0.9058   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1ccde4df98>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1st model\n",
    "#model.fit(x_train, y_train, batch_size=128, epochs=10)\n",
    "#2nd model\n",
    "model.fit(x_train_vgg, y_train_vgg, batch_size=128, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set test size to 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "x_test_vgg = np.zeros((10000,64,64,3))\n",
    "\n",
    "for i in range(10000):\n",
    "    x_test_vgg[i] = transform.resize(x_test[i], (64, 64), order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print (x_test_vgg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 22s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29330722105503082, 0.89910000000000001]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_vgg, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
